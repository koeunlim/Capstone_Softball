{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "refined-clause",
   "metadata": {},
   "source": [
    "## [NYCDSA Capstone Project] \n",
    "# Women's Softball League Power Ranking Estimate\n",
    "\n",
    "<br>\n",
    "Koeun Lim (ke.lim.kang@gmail.com)<br>\n",
    "Kevin Haghi (kevin.haghi@gmail.com)<br>\n",
    "\n",
    "\n",
    "# Step 1. Web scraping\n",
    "\n",
    "---\n",
    "## Project Description\n",
    "\n",
    "\n",
    "\n",
    "### Project Outline\n",
    "- Step 1. Web scraping\n",
    "- Step 2. EDA\n",
    "- Step 3. Modeling\n",
    "- Step 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "built-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "associate-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "\n",
    "# load the first page\n",
    "url = 'http://stats.ncaa.org/rankings/'\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "select_sport = Select(driver.find_element_by_id('sport'))\n",
    "select_sport.select_by_visible_text('Softball')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "intensive-opinion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-13\n",
      "Batting Average\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koeunlim/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:79: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-13\n",
      "Double Plays per Game\n",
      "2012-13\n",
      "Doubles per Game\n",
      "2012-13\n",
      "Earned Run Average\n",
      "2012-13\n",
      "Fielding Percentage\n",
      "2012-13\n",
      "Home Runs per game\n",
      "2012-13\n",
      "Scoring\n",
      "2012-13\n",
      "Slugging Percentage\n",
      "2012-13\n",
      "Stolen Bases per Game\n",
      "2012-13\n",
      "Triples per Game\n",
      "2012-13\n",
      "WL Percentage\n"
     ]
    }
   ],
   "source": [
    "Seasons = ['2018-19','2017-18','2016-17','2015-16','2014-15','2013-14','2012-13']\n",
    "### Loop through all academic years\n",
    "for idx_seasons in range(len(Seasons)):\n",
    "    select_season = Select(driver.find_element_by_id('acadyr'))\n",
    "    select_season.select_by_visible_text(Seasons[idx_seasons])\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Select division\n",
    "    select_div = Select(driver.find_element_by_id('u_div'))\n",
    "    select_div.select_by_visible_text('I')\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Select period\n",
    "    select_period = Select(driver.find_element_by_id('rp'))\n",
    "\n",
    "    period_box = driver.find_element_by_name('rp')\n",
    "    period_options = [x for x in period_box.find_elements_by_tag_name('option')]\n",
    "    for period_option in period_options:\n",
    "        period_text = period_option.text\n",
    "        if 'Final Statistics' in period_text:\n",
    "            select_period.select_by_visible_text(period_text)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Click team tab\n",
    "    select_team = driver.find_element_by_id('stat_type_T_N')\n",
    "    select_team.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Select through stats\n",
    "    stats_box = driver.find_element_by_name('Stats')\n",
    "    stats_options = [x for x in stats_box.find_elements_by_tag_name('option')]\n",
    "    Stats_names = []\n",
    "    for idx_stats, stats_option in enumerate(stats_options):\n",
    "        Stats_names.append(stats_option.text)\n",
    "    del Stats_names[0]\n",
    "\n",
    "    select_stats = Select(driver.find_element_by_id('Stats'))\n",
    "    select_stats.select_by_visible_text(Stats_names[0])\n",
    "    time.sleep(2)\n",
    "\n",
    "    ### Loop through stats\n",
    "    for idx_stats in range(len(Stats_names)):\n",
    "        select_stats1 = Select(driver.find_element_by_id('stat_seq')) # id changes after the initial select\n",
    "        select_stats1.select_by_visible_text(Stats_names[idx_stats])\n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(Seasons[idx_seasons])\n",
    "        print(Stats_names[idx_stats])\n",
    "        # Select max the length of the table\n",
    "        try:\n",
    "            select_len = Select(driver.find_element_by_name('rankings_table_length'))\n",
    "            select_len.select_by_value('-1')\n",
    "            time.sleep(1)\n",
    "\n",
    "            len_str = driver.find_element_by_id('rankings_table_info').text\n",
    "            num_obs = max([int(s) for s in len_str.split() if s.isdigit()])\n",
    "        except:\n",
    "            print('No table length')\n",
    "\n",
    "        ### Scrape ===============================\n",
    "        soup_level1=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        table1 = soup_level1.find(\"table\", attrs={\"id\": \"rankings_table\"})\n",
    "\n",
    "        # Obtain table header\n",
    "        table_data1 = table1.tbody.find_all(\"tr\") \n",
    "        table_header = []\n",
    "        for th in table1.find_all(\"th\"):\n",
    "            table_header.append(th.text.replace('\\n', ' ').strip())\n",
    "\n",
    "        # Obtain table\n",
    "        table_data = pd.DataFrame(columns = table_header)\n",
    "        t_data = {}\n",
    "        for tr in table1.tbody.find_all(\"tr\"): \n",
    "            for idx_td,td in enumerate(tr.find_all(\"td\")): \n",
    "                t_data[table_header[idx_td]] = td.text.replace('\\n', '').strip()\n",
    "            table_data = table_data.append(t_data,ignore_index=True)\n",
    "        table_data['Team'] = table_data['Team'].str.replace(r'\\(.*\\)','')    \n",
    "        table_data = table_data.rename(columns={'Team':'College'})\n",
    "\n",
    "        # Export to csv\n",
    "        fname = 'Data/NCAAstats/' + Stats_names[idx_stats].replace(' ','_') + '_' + Seasons[idx_seasons][0:2] + Seasons[idx_seasons][5:7] + '.csv'\n",
    "        table_data.to_csv(fname,index=False)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-directory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
